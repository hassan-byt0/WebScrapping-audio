{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97jDW6dhYI0_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzqLZrA2UEmL"
      },
      "source": [
        "## Task 1: Semantic Chunking of a Youtube Video\n",
        "\n",
        "**Problem Statement:**\n",
        "\n",
        "The objective is to extract high-quality, meaningful (semantic) segments from the specified YouTube video: [Watch Video](https://www.youtube.com/watch?v=Sby1uJ_NFIY).\n",
        "\n",
        "Suggested workflow:\n",
        "1. **Download Video and Extract Audio:** Download the video and separate the audio component.\n",
        "2. **Transcription of Audio:** Utilize an open-source Speech-to-Text model to transcribe the audio. *Provide an explanation of the chosen model and any techniques used to enhance the quality of the transcription.*\n",
        "3. **Time-Align Transcript with Audio:** *Describe the methodology and steps for aligning the transcript with the audio.*\n",
        "4. **Semantic Chunking of Data:** Slice the data into audio-text pairs, using both semantic information from the text and voice activity information from the audio, with each audio-chunk being less than 15s in length. *Explain the logic used for semantic chunking and discuss the strengths and weaknesses of your approach.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKSUWjlWDIv3"
      },
      "source": [
        "# Task 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q3RJ2zVDR1L"
      },
      "source": [
        "Step 1: Downloading dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Mb1nZhjymg",
        "outputId": "7736eba5-20b7-478b-f8f4-40ebfbbd7523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m347.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "#following modules to download youtube video\n",
        "!pip install pytube\n",
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obtMtWbaDfJ3"
      },
      "source": [
        "Choice of Speech-to-Text Model: WhisperAI by OpenAI\n",
        "\n",
        "Reason:\n",
        "WhisperAI by OpenAI is chosen due to its straightforward installation process and robust feature set.\n",
        "\n",
        "It supports the creation of various file formats such as txt, vtt, srt, and tsv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5witnR10jyjb",
        "outputId": "bd89b304-9d9f-4eaf-feb5-7f9932c28e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-aekpmzb1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-aekpmzb1\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=1644e5d6d4870c84b95a90b55aa2490cefc303c1341a737c689a69884557f92c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t3r8_11n/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,118 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,083 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,374 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,848 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,383 kB]\n",
            "Fetched 9,040 kB in 1s (6,111 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ],
      "source": [
        " # installing WhisperAi\n",
        " !pip install git+https://github.com/openai/whisper.git\n",
        " !sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H46_6jAJjyZa"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIJImQBqD-ut"
      },
      "source": [
        "Step 2 : Downlaoding video from youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-bD1a8GjyNf"
      },
      "outputs": [],
      "source": [
        "# Download video\n",
        "video_url = \"https://www.youtube.com/watch?v=Sby1uJ_NFIY\"\n",
        "yt = YouTube(video_url)\n",
        "yt.streams.filter(only_audio=True).first().download(filename='video')\n",
        "\n",
        "# Specify the full path to the video file\n",
        "video_path = \"/content/video\"\n",
        "\n",
        "# Extract audio using ffmpeg\n",
        "subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', 'audio.wav'], check=True)\n",
        "\n",
        "# Remove the video file\n",
        "os.remove(video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY9haOnnEHts"
      },
      "source": [
        "Step 3: Transcription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIEm8U6Nj9rX"
      },
      "outputs": [],
      "source": [
        "# using whisper for trascipting\n",
        "transcript = !whisper \"audio.wav\" --model medium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ4SGtyuELZo"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WHdHVDPj9kK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def8206e-7985-4fc1-c43b-d0ac8aa05ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'chunk_id': 1, 'chunk_length': 15, 'text': '/content/audio.txt', 'start_time': 0, 'end_time': 1}]\n"
          ]
        }
      ],
      "source": [
        "# Split transcript into chunks\n",
        "chunk_duration = 15  # in seconds\n",
        "trascript_txt = '/content/audio.txt' # using txt format file obtained\n",
        "words = trascript_txt.split()\n",
        "num_chunks = len(words) // chunk_duration + 1\n",
        "\n",
        "# for allignment of the time stamp of audio with text, tsc obtained is enough\n",
        "\n",
        "# Generate chunks with start and end times\n",
        "chunks = []\n",
        "for i in range(num_chunks):\n",
        "    start_time = i * chunk_duration\n",
        "    end_time = min((i + 1) * chunk_duration, len(words))\n",
        "    text_chunk = ' '.join(words[start_time:end_time])\n",
        "    chunks.append({\n",
        "        \"chunk_id\": i + 1,\n",
        "        \"chunk_length\": chunk_duration,\n",
        "        \"text\": text_chunk,\n",
        "        \"start_time\": start_time,\n",
        "        \"end_time\": end_time\n",
        "    })\n",
        "\n",
        "print(chunks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzYZmZStEUK3"
      },
      "source": [
        "\n",
        "Step 5: Semantic Chunking\n",
        "\n",
        "The purpose of semantic chunking is to split the text into meaningful and important segments. This can be achieved by using models like BERT to identify named entities or performing sentiment analysis to capture impactful words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXHi79eyj9Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf06d9bd-3ff2-4d15-8508-80b28fefb887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'chunk_id': 1, 'chunk_length': 15, 'text': '/content/audio.txt', 'start_time': 0, 'end_time': 1}]\n"
          ]
        }
      ],
      "source": [
        "# Semantic Chunking\n",
        "def semantic_chunking(chunks):\n",
        "    semantic_chunks = []\n",
        "    for chunk in chunks:\n",
        "        # Here, we simply consider each chunk as a semantic chunk\n",
        "        # asuming every chunk is of importance\n",
        "        semantic_chunks.append(chunk)\n",
        "    return semantic_chunks\n",
        "\n",
        "# Apply semantic chunking\n",
        "semantic_chunks = semantic_chunking(chunks)\n",
        "print(semantic_chunks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt7gGd4f9cV_"
      },
      "source": [
        "# **Bonus**\n",
        "\n",
        "3.1: Implemended Gradio as interface\n",
        "\n",
        "Here, by textbox will input link of youtube videos to extract their transcripted text of video.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRH2BUL_9lu7"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "import subprocess\n",
        "# defining answer function for gradio inputs\n",
        "def downloading(link):\n",
        "  video_url = link\n",
        "  yt = YouTube(video_url)\n",
        "  yt.streams.filter(only_audio=True).first().download(filename='video2')\n",
        "\n",
        "  # Specify the full path to the video file\n",
        "  video_path = \"/content/video2\"\n",
        "\n",
        "  # Extract audio using ffmpeg\n",
        "  subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', 'audio2.wav'], check=True)\n",
        "\n",
        "  # Remove the video file\n",
        "  os.remove(video_path)\n",
        "  transcript = !whisper \"audio2.wav\" --model medium\n",
        "  return transcript\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtJ7XJUm9svR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b831ffc-bed2-4547-8588-6930da073b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.31.3-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.3 (from gradio)\n",
            "  Downloading gradio_client-0.16.3-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.3->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.3->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=30618b4979c51ad0cdde080140447daba9d9b4a3aaf383cce6695137c1cbda86\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 ffmpy-0.3.2 gradio-4.31.3 gradio-client-0.16.3 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While running below cell\n",
        "dekete any file related to audio2 in any format from /content folder since it will detect it if it exist and wont run\n",
        "\n",
        "and also sometimes it gives error in many cases so try running multiple times"
      ],
      "metadata": {
        "id": "eAl_OzGpF_uM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQOmneVO9wZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "efd3ddc0-e6f9-4f95-c885-b5a184fc8086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://8b4b33f65ea8a33b33.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8b4b33f65ea8a33b33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from gradio.components import Textbox\n",
        "\n",
        "# Creating the interface using Gradio\n",
        "iface = gr.Interface(\n",
        "    fn= downloading,\n",
        "    inputs=Textbox(lines=2, label=\"Enter a link of youtube video\"),\n",
        "    outputs=Textbox(lines=15,label=\"Transcrpted text:\"),\n",
        "    live=True,\n",
        "    title=\"Transcription process on youtube video\",\n",
        "    description=\"Extraction of audio and converting it to text using WhisperAI\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISRJCK5LFuC7"
      },
      "source": [
        "Bonus 3.2:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBt8cbX_WpQf"
      },
      "source": [
        "## Task 2: Exploratory Data Analysis of New Testament Audio and Text\n",
        "\n",
        "**Problem Statement:**\n",
        "\n",
        "The objective of this task is to conduct a comprehensive exploratory data analysis (EDA) on the audio and text data of the 260 chapters of the New Testament in your mother tongue (excluding English). The data should be obtained through web scraping from [Faith Comes By Hearing](https://www.faithcomesbyhearing.com/).\n",
        "\n",
        "The workflow for this task should include:\n",
        "1. **Web Scraping:** Systematically download the audio files and their corresponding textual content for each of the 260 chapters of the New Testament from the specified website.\n",
        "2. **Data Preparation:** Organize the data by chapters, ensuring each audio file is matched with its corresponding text.\n",
        "3. **Exploratory Data Analysis:** Analyze the data to uncover patterns, anomalies, or insights that could benefit applications such as Text to Speech (TTS) and Speech to Text (STT) technologies. Your analysis should explore various facets of the data, including audio quality, text clarity, and alignment between text and spoken content.\n",
        "\n",
        "**Judgement Criteria:**\n",
        "\n",
        "Your submission will be evaluated based on:\n",
        "- **Efficiency and Reliability of Web Scraping Techniques:** The methods and tools used for downloading the chapters efficiently and reliably.\n",
        "- **Data Analysis Methods:** The techniques and approaches used for analyzing the audio and text data.\n",
        "- **Quality of Data Analysis:** How effectively the analysis addresses potential applications for the Speech team, including TTS and STT technologies.\n",
        "- **Creativity in Analysis:** Innovative approaches in data handling and analysis, and the use of relevant metrics to assess data quality and applicability.\n",
        "\n",
        "**Submission Requirements:**\n",
        "\n",
        "Your submission should include the following components:\n",
        "- **Report on Key Performance Indicators (KPIs):** A concise report detailing the key findings from your analysis, focusing on aspects that are critical for improving TTS and STT applications.\n",
        "- **Methodological Explanation:** A thorough explanation of the methods used for both web scraping and the exploratory data analysis. This should include challenges faced and how they were overcome.\n",
        "- **Supporting Materials:** Include code snippets and visualizations that highlight significant insights from the data. These should be well-documented and easy to understand, demonstrating the logic behind your analytical decisions.\n",
        "\n",
        "The report should be structured to clearly present the methodology, findings, and implications of your analysis. It should be technical yet accessible, aimed at stakeholders who may have varying levels of familiarity with data analysis techniques.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ip482i_kJhG"
      },
      "source": [
        "It was a challenging and interesting task!\n",
        " Conducting an exploratory data analysis on audio and text data for the web scrapped data obtained from New Testament in a language other than English,\n",
        "\n",
        " following are steps i did:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ymgn3sGoluq"
      },
      "source": [
        "Step 1. **Web Scraping:**\n",
        "   \n",
        "   Used Beautiful Soup to systematically download audio files and their corresponding textual content for each of the 260 chapters from the Faith Comes By Hearing website for Hindi language.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap9r1D98kPHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30654c81-1c85-4149-a612-055a6a6b55fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGs9n8Drk38X"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup # web scrapping\n",
        "from urllib.parse import unquote # to properly encode extracted url\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Em1dlk50wlX"
      },
      "outputs": [],
      "source": [
        "def scrape_audio_and_text():\n",
        "    base_url = \"https://live.bible.is/bible/\"\n",
        "    language_code = \"hinohc\"\n",
        "    book_code = \"gen\"\n",
        "    chapters = 260\n",
        "    # Create directories if they don't exist\n",
        "    if not os.path.exists(\"audio\"):\n",
        "        os.makedirs(\"audio\")\n",
        "    if not os.path.exists(\"text\"):\n",
        "        os.makedirs(\"text\")\n",
        "\n",
        "    for chapter in range(1, chapters + 1):\n",
        "        url = f\"{base_url}{language_code}/{book_code}/{chapter}\"\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Extract text content since text element stored in div tag class chapter justify\n",
        "        text_element = soup.find(\"div\", class_=\"chapter justify\")\n",
        "        if text_element:\n",
        "            text_content = text_element.get_text(strip=True)\n",
        "            with open(f\"text/{book_code}_{chapter}.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
        "                text_file.write(text_content)\n",
        "            print(f\"Text for chapter {chapter} downloaded.\")\n",
        "        else:\n",
        "            print(f\"No text found for chapter {chapter}.\")\n",
        "\n",
        "        # Extract audio URL from video tag class audio_player src content\n",
        "        video_tag = soup.find(\"video\", class_=\"audio_player\")\n",
        "        audio_url = None\n",
        "        if video_tag:\n",
        "            audio_src = video_tag.get(\"src\")\n",
        "            audio_url = unquote(audio_src)\n",
        "            print(audio_url)\n",
        "        if audio_url:\n",
        "            #audio_url = unquote(audio_src)\n",
        "            audio_response = requests.get(audio_url)\n",
        "\n",
        "            with open(f\"audio/{book_code}_{chapter}.mp3\", \"wb\") as audio_file:\n",
        "                audio_file.write(audio_response.content)\n",
        "            print(f\"Audio for chapter {chapter} downloaded.\")\n",
        "        else:\n",
        "            print(f\"No audio found for chapter {chapter}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay so biggest problem i m facing is extraction of audio url from video tag by extracting link from src But\n",
        "\n",
        "By printing it is showing _ which maybe becuase it is not getting extracting properly\n",
        "\n",
        "So one thing we can do is by inspection manually copy paste link in directory and then extract them by iterating"
      ],
      "metadata": {
        "id": "ZgV-fYQvnyom"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUCOLGYwoxOV"
      },
      "source": [
        "Step 2. **Data Preparation:**\n",
        "   \n",
        "   Organize the data by chapters, ensuring that each audio file is correctly matched with its corresponding text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csIj38rq0wcm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_data():\n",
        "    audio_data = []\n",
        "    text_data = []\n",
        "    chapters = 260\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(\"audio\", exist_ok=True)\n",
        "    os.makedirs(\"text\", exist_ok=True)\n",
        "\n",
        "    for chapter in range(1, chapters + 1):\n",
        "        audio_file_path = f\"audio/{chapter}.mp3\"\n",
        "        text_file_path = f\"text/{chapter}.txt\"\n",
        "\n",
        "        if os.path.exists(audio_file_path):\n",
        "            with open(audio_file_path, \"rb\") as audio_file:\n",
        "                audio_data.append(audio_file.read())\n",
        "\n",
        "        if os.path.exists(text_file_path):\n",
        "            with open(text_file_path, \"r\", encoding=\"utf-8\") as text_file:\n",
        "                text_data.append(text_file.read())\n",
        "\n",
        "    return audio_data, text_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49YXZRDqoxvr"
      },
      "source": [
        "Step 3. **Exploratory Data Analysis:**\n",
        "   \n",
        "   Tried to used visualization techniques to find any discontinuity in audio file.\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_iCbOuB057P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Visualize audio data\n",
        "def visualize_audio(audio_file_path):\n",
        "    # Load audio file\n",
        "    audio_data, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    # Plot audio waveform\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(audio_data, sr=sr)\n",
        "    plt.title('Audio Waveform')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QM6YD5b1AlF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26d9766c-12ec-47e9-9385-a88bc5e760f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text for chapter 1 downloaded.\n",
            "No audio found for chapter 1.\n",
            "Text for chapter 2 downloaded.\n",
            "No audio found for chapter 2.\n",
            "Text for chapter 3 downloaded.\n",
            "No audio found for chapter 3.\n",
            "Text for chapter 4 downloaded.\n",
            "No audio found for chapter 4.\n",
            "Text for chapter 5 downloaded.\n",
            "No audio found for chapter 5.\n",
            "Text for chapter 6 downloaded.\n",
            "No audio found for chapter 6.\n",
            "Text for chapter 7 downloaded.\n",
            "No audio found for chapter 7.\n",
            "Text for chapter 8 downloaded.\n",
            "No audio found for chapter 8.\n",
            "Text for chapter 9 downloaded.\n",
            "No audio found for chapter 9.\n",
            "Text for chapter 10 downloaded.\n",
            "No audio found for chapter 10.\n",
            "Text for chapter 11 downloaded.\n",
            "No audio found for chapter 11.\n",
            "Text for chapter 12 downloaded.\n",
            "No audio found for chapter 12.\n",
            "Text for chapter 13 downloaded.\n",
            "No audio found for chapter 13.\n",
            "Text for chapter 14 downloaded.\n",
            "No audio found for chapter 14.\n",
            "Text for chapter 15 downloaded.\n",
            "No audio found for chapter 15.\n",
            "Text for chapter 16 downloaded.\n",
            "No audio found for chapter 16.\n",
            "Text for chapter 17 downloaded.\n",
            "No audio found for chapter 17.\n",
            "Text for chapter 18 downloaded.\n",
            "No audio found for chapter 18.\n",
            "Text for chapter 19 downloaded.\n",
            "No audio found for chapter 19.\n",
            "Text for chapter 20 downloaded.\n",
            "No audio found for chapter 20.\n",
            "Text for chapter 21 downloaded.\n",
            "No audio found for chapter 21.\n",
            "Text for chapter 22 downloaded.\n",
            "No audio found for chapter 22.\n",
            "Text for chapter 23 downloaded.\n",
            "No audio found for chapter 23.\n",
            "Text for chapter 24 downloaded.\n",
            "No audio found for chapter 24.\n",
            "Text for chapter 25 downloaded.\n",
            "No audio found for chapter 25.\n",
            "Text for chapter 26 downloaded.\n",
            "No audio found for chapter 26.\n",
            "Text for chapter 27 downloaded.\n",
            "No audio found for chapter 27.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text for chapter 28 downloaded.\n",
            "No audio found for chapter 28.\n",
            "Text for chapter 29 downloaded.\n",
            "No audio found for chapter 29.\n",
            "Text for chapter 30 downloaded.\n",
            "No audio found for chapter 30.\n",
            "Text for chapter 31 downloaded.\n",
            "No audio found for chapter 31.\n",
            "Text for chapter 32 downloaded.\n",
            "No audio found for chapter 32.\n",
            "Text for chapter 33 downloaded.\n",
            "No audio found for chapter 33.\n",
            "Text for chapter 34 downloaded.\n",
            "No audio found for chapter 34.\n",
            "Text for chapter 35 downloaded.\n",
            "No audio found for chapter 35.\n",
            "Text for chapter 36 downloaded.\n",
            "No audio found for chapter 36.\n",
            "No text found for chapter 37.\n",
            "No audio found for chapter 37.\n",
            "Text for chapter 38 downloaded.\n",
            "No audio found for chapter 38.\n",
            "Text for chapter 39 downloaded.\n",
            "No audio found for chapter 39.\n",
            "No text found for chapter 40.\n",
            "No audio found for chapter 40.\n",
            "Text for chapter 41 downloaded.\n",
            "No audio found for chapter 41.\n",
            "Text for chapter 42 downloaded.\n",
            "No audio found for chapter 42.\n",
            "No text found for chapter 43.\n",
            "No audio found for chapter 43.\n",
            "No text found for chapter 44.\n",
            "No audio found for chapter 44.\n",
            "No text found for chapter 45.\n",
            "No audio found for chapter 45.\n",
            "No text found for chapter 46.\n",
            "No audio found for chapter 46.\n",
            "No text found for chapter 47.\n",
            "No audio found for chapter 47.\n",
            "Text for chapter 48 downloaded.\n",
            "No audio found for chapter 48.\n",
            "Text for chapter 49 downloaded.\n",
            "No audio found for chapter 49.\n",
            "No text found for chapter 50.\n",
            "No audio found for chapter 50.\n",
            "No text found for chapter 51.\n",
            "No audio found for chapter 51.\n",
            "No text found for chapter 52.\n",
            "No audio found for chapter 52.\n",
            "No text found for chapter 53.\n",
            "No audio found for chapter 53.\n",
            "No text found for chapter 54.\n",
            "No audio found for chapter 54.\n",
            "No text found for chapter 55.\n",
            "No audio found for chapter 55.\n",
            "No text found for chapter 56.\n",
            "No audio found for chapter 56.\n",
            "No text found for chapter 57.\n",
            "No audio found for chapter 57.\n",
            "No text found for chapter 58.\n",
            "No audio found for chapter 58.\n",
            "No text found for chapter 59.\n",
            "No audio found for chapter 59.\n",
            "No text found for chapter 60.\n",
            "No audio found for chapter 60.\n",
            "No text found for chapter 61.\n",
            "No audio found for chapter 61.\n",
            "No text found for chapter 62.\n",
            "No audio found for chapter 62.\n",
            "No text found for chapter 63.\n",
            "No audio found for chapter 63.\n",
            "No text found for chapter 64.\n",
            "No audio found for chapter 64.\n",
            "No text found for chapter 65.\n",
            "No audio found for chapter 65.\n",
            "No text found for chapter 66.\n",
            "No audio found for chapter 66.\n",
            "No text found for chapter 67.\n",
            "No audio found for chapter 67.\n",
            "No text found for chapter 68.\n",
            "No audio found for chapter 68.\n",
            "No text found for chapter 69.\n",
            "No audio found for chapter 69.\n",
            "No text found for chapter 70.\n",
            "No audio found for chapter 70.\n",
            "No text found for chapter 71.\n",
            "No audio found for chapter 71.\n",
            "No text found for chapter 72.\n",
            "No audio found for chapter 72.\n",
            "No text found for chapter 73.\n",
            "No audio found for chapter 73.\n",
            "No text found for chapter 74.\n",
            "No audio found for chapter 74.\n",
            "No text found for chapter 75.\n",
            "No audio found for chapter 75.\n",
            "No text found for chapter 76.\n",
            "No audio found for chapter 76.\n",
            "No text found for chapter 77.\n",
            "No audio found for chapter 77.\n",
            "No text found for chapter 78.\n",
            "No audio found for chapter 78.\n",
            "No text found for chapter 79.\n",
            "No audio found for chapter 79.\n",
            "No text found for chapter 80.\n",
            "No audio found for chapter 80.\n",
            "No text found for chapter 81.\n",
            "No audio found for chapter 81.\n",
            "No text found for chapter 82.\n",
            "No audio found for chapter 82.\n",
            "No text found for chapter 83.\n",
            "No audio found for chapter 83.\n",
            "No text found for chapter 84.\n",
            "No audio found for chapter 84.\n",
            "No text found for chapter 85.\n",
            "No audio found for chapter 85.\n",
            "No text found for chapter 86.\n",
            "No audio found for chapter 86.\n",
            "No text found for chapter 87.\n",
            "No audio found for chapter 87.\n",
            "No text found for chapter 88.\n",
            "No audio found for chapter 88.\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "No text found for chapter 89.\n",
            "No audio found for chapter 89.\n",
            "No text found for chapter 90.\n",
            "No audio found for chapter 90.\n",
            "No text found for chapter 91.\n",
            "No audio found for chapter 91.\n",
            "No text found for chapter 92.\n",
            "No audio found for chapter 92.\n",
            "Detected language: English\n",
            "No text found for chapter 93.\n",
            "No audio found for chapter 93.\n",
            "No text found for chapter 94.\n",
            "No audio found for chapter 94.\n",
            "No text found for chapter 95.\n",
            "No audio found for chapter 95.\n",
            "No text found for chapter 96.\n",
            "No audio found for chapter 96.\n",
            "No text found for chapter 97.\n",
            "No audio found for chapter 97.\n",
            "No text found for chapter 98.\n",
            "No audio found for chapter 98.\n",
            "No text found for chapter 99.\n",
            "No audio found for chapter 99.\n",
            "No text found for chapter 100.\n",
            "No audio found for chapter 100.\n",
            "No text found for chapter 101.\n",
            "No audio found for chapter 101.\n",
            "No text found for chapter 102.\n",
            "No audio found for chapter 102.\n",
            "No text found for chapter 103.\n",
            "No audio found for chapter 103.\n",
            "No text found for chapter 104.\n",
            "No audio found for chapter 104.\n",
            "No text found for chapter 105.\n",
            "No audio found for chapter 105.\n",
            "No text found for chapter 106.\n",
            "No audio found for chapter 106.\n",
            "No text found for chapter 107.\n",
            "No audio found for chapter 107.\n",
            "No text found for chapter 108.\n",
            "No audio found for chapter 108.\n",
            "No text found for chapter 109.\n",
            "No audio found for chapter 109.\n",
            "No text found for chapter 110.\n",
            "No audio found for chapter 110.\n",
            "No text found for chapter 111.\n",
            "No audio found for chapter 111.\n",
            "[00:00.000 --> 00:01.840]  Hi everyone, Kevin here.\n",
            "[00:01.840 --> 00:05.600]  Today, we're going to look at how you can take speech\n",
            "[00:05.600 --> 00:09.480]  and turn it into text using AI.\n",
            "[00:09.480 --> 00:13.440]  And the really crazy thing is that it does a better job\n",
            "[00:13.440 --> 00:15.440]  than most humans.\n",
            "[00:15.440 --> 00:19.560]  You can use it with English and 96 other languages.\n",
            "[00:19.560 --> 00:22.600]  It works even if you have a lot of background noise.\n",
            "[00:22.600 --> 00:26.840]  And it also works if you have a very sick accent.\n",
            "No text found for chapter 112.\n",
            "No audio found for chapter 112.\n",
            "No text found for chapter 113.\n",
            "No audio found for chapter 113.\n",
            "No text found for chapter 114.\n",
            "No audio found for chapter 114.\n",
            "No text found for chapter 115.\n",
            "No audio found for chapter 115.\n",
            "No text found for chapter 116.\n",
            "No audio found for chapter 116.\n",
            "No text found for chapter 117.\n",
            "No audio found for chapter 117.\n",
            "No text found for chapter 118.\n",
            "No audio found for chapter 118.\n",
            "No text found for chapter 119.\n",
            "No audio found for chapter 119.\n",
            "No text found for chapter 120.\n",
            "No audio found for chapter 120.\n",
            "No text found for chapter 121.\n",
            "No audio found for chapter 121.\n",
            "No text found for chapter 122.\n",
            "No audio found for chapter 122.\n",
            "No text found for chapter 123.\n",
            "No audio found for chapter 123.\n",
            "No text found for chapter 124.\n",
            "No audio found for chapter 124.\n",
            "No text found for chapter 125.\n",
            "No audio found for chapter 125.\n",
            "No text found for chapter 126.\n",
            "No audio found for chapter 126.\n",
            "No text found for chapter 127.\n",
            "No audio found for chapter 127.\n",
            "No text found for chapter 128.\n",
            "No audio found for chapter 128.\n",
            "No text found for chapter 129.\n",
            "No audio found for chapter 129.\n",
            "No text found for chapter 130.\n",
            "No audio found for chapter 130.\n",
            "[00:27.760 --> 00:30.840]  The best part is that it's completely free\n",
            "[00:30.840 --> 00:32.400]  and also open source.\n",
            "[00:33.440 --> 00:35.200]  Let's check out how to do this.\n",
            "[00:35.200 --> 00:38.160]  We're going to use an AI tool called Whisper.\n",
            "[00:39.200 --> 00:42.480]  Whisper is made by a company called OpenAI,\n",
            "[00:42.480 --> 00:45.120]  and you might've heard of them before.\n",
            "[00:45.120 --> 00:48.400]  That's the same company behind the immensely popular\n",
            "[00:48.400 --> 00:53.240]  chat GPT, which allows you to converse with a computer.\n",
            "[00:53.240 --> 00:55.740]  There are also the company behind Dolly2,\n",
            "No text found for chapter 131.\n",
            "No audio found for chapter 131.\n",
            "No text found for chapter 132.\n",
            "No audio found for chapter 132.\n",
            "No text found for chapter 133.\n",
            "No audio found for chapter 133.\n",
            "No text found for chapter 134.\n",
            "No audio found for chapter 134.\n",
            "No text found for chapter 135.\n",
            "No audio found for chapter 135.\n",
            "No text found for chapter 136.\n",
            "No audio found for chapter 136.\n",
            "No text found for chapter 137.\n",
            "No audio found for chapter 137.\n",
            "No text found for chapter 138.\n",
            "No audio found for chapter 138.\n",
            "No text found for chapter 139.\n",
            "No audio found for chapter 139.\n",
            "No text found for chapter 140.\n",
            "No audio found for chapter 140.\n",
            "No text found for chapter 141.\n",
            "No audio found for chapter 141.\n",
            "No text found for chapter 142.\n",
            "No audio found for chapter 142.\n",
            "No text found for chapter 143.\n",
            "No audio found for chapter 143.\n",
            "No text found for chapter 144.\n",
            "No audio found for chapter 144.\n",
            "No text found for chapter 145.\n",
            "No audio found for chapter 145.\n",
            "No text found for chapter 146.\n",
            "No audio found for chapter 146.\n",
            "No text found for chapter 147.\n",
            "No audio found for chapter 147.\n",
            "No text found for chapter 148.\n",
            "No audio found for chapter 148.\n",
            "No text found for chapter 149.\n",
            "No audio found for chapter 149.\n",
            "No text found for chapter 150.\n",
            "No audio found for chapter 150.\n",
            "No text found for chapter 151.\n",
            "No audio found for chapter 151.\n",
            "No text found for chapter 152.\n",
            "No audio found for chapter 152.\n",
            "[00:55.780 --> 00:57.500]  where you can type in some text\n",
            "[00:57.500 --> 01:00.900]  and then it'll generate an image based on that text.\n",
            "[01:01.780 --> 01:04.340]  You can install Whisper directly on your computer.\n",
            "[01:04.340 --> 01:06.280]  You can click on the link right up above,\n",
            "[01:06.280 --> 01:09.620]  but you do need a somewhat capable computer.\n",
            "[01:09.620 --> 01:12.140]  So instead, we're going to use something called\n",
            "[01:12.140 --> 01:14.100]  Google Collaboratory.\n",
            "[01:14.100 --> 01:17.280]  This allows you to run code directly in your web browser.\n",
            "[01:17.280 --> 01:20.660]  So it doesn't really matter what type of PC you have.\n",
            "[01:20.660 --> 01:24.340]  To use Google Collaboratory, head to Google Drive.\n",
            "No text found for chapter 153.\n",
            "No audio found for chapter 153.\n",
            "No text found for chapter 154.\n",
            "No audio found for chapter 154.\n",
            "No text found for chapter 155.\n",
            "No audio found for chapter 155.\n",
            "No text found for chapter 156.\n",
            "No audio found for chapter 156.\n",
            "No text found for chapter 157.\n",
            "No audio found for chapter 157.\n",
            "No text found for chapter 158.\n",
            "No audio found for chapter 158.\n",
            "No text found for chapter 159.\n",
            "No audio found for chapter 159.\n",
            "No text found for chapter 160.\n",
            "No audio found for chapter 160.\n",
            "No text found for chapter 161.\n",
            "No audio found for chapter 161.\n",
            "No text found for chapter 162.\n",
            "No audio found for chapter 162.\n",
            "No text found for chapter 163.\n",
            "No audio found for chapter 163.\n",
            "No text found for chapter 164.\n",
            "No audio found for chapter 164.\n",
            "No text found for chapter 165.\n",
            "No audio found for chapter 165.\n",
            "No text found for chapter 166.\n",
            "No audio found for chapter 166.\n",
            "No text found for chapter 167.\n",
            "No audio found for chapter 167.\n",
            "No text found for chapter 168.\n",
            "No audio found for chapter 168.\n",
            "No text found for chapter 169.\n",
            "No audio found for chapter 169.\n",
            "No text found for chapter 170.\n",
            "No audio found for chapter 170.\n",
            "No text found for chapter 171.\n",
            "No audio found for chapter 171.\n",
            "No text found for chapter 172.\n",
            "No audio found for chapter 172.\n",
            "No text found for chapter 173.\n",
            "No audio found for chapter 173.\n",
            "No text found for chapter 174.\n",
            "No audio found for chapter 174.\n",
            "No text found for chapter 175.\n",
            "No audio found for chapter 175.\n",
            "No text found for chapter 176.\n",
            "No audio found for chapter 176.\n",
            "No text found for chapter 177.\n",
            "No audio found for chapter 177.\n",
            "No text found for chapter 178.\n",
            "No audio found for chapter 178.\n",
            "No text found for chapter 179.\n",
            "No audio found for chapter 179.\n",
            "No text found for chapter 180.\n",
            "No audio found for chapter 180.\n",
            "No text found for chapter 181.\n",
            "No audio found for chapter 181.\n",
            "No text found for chapter 182.\n",
            "No audio found for chapter 182.\n",
            "No text found for chapter 183.\n",
            "No audio found for chapter 183.\n",
            "[01:24.380 --> 01:26.820]  You can click on the link right up above.\n",
            "[01:26.820 --> 01:28.500]  You'll need a Google account,\n",
            "[01:28.500 --> 01:30.180]  and if you don't have one yet,\n",
            "[01:30.180 --> 01:32.780]  it's entirely free to set up.\n",
            "[01:32.780 --> 01:35.260]  On Google Drive, in the top left-hand corner,\n",
            "[01:35.260 --> 01:37.100]  let's click on the new button.\n",
            "[01:37.100 --> 01:39.580]  And at the very bottom, let's click on more,\n",
            "[01:39.580 --> 01:42.300]  and then go down to connect more apps.\n",
            "[01:42.300 --> 01:43.860]  At the top of this dialogue,\n",
            "[01:43.860 --> 01:45.620]  let's click into the search field,\n",
            "[01:45.620 --> 01:49.620]  and here type in Google Collaboratory and then search.\n",
            "[01:49.620 --> 01:52.020]  Here, we see this result for Collaboratory.\n",
            "[01:52.020 --> 01:53.480]  Let's click on that.\n",
            "No text found for chapter 184.\n",
            "No audio found for chapter 184.\n",
            "No text found for chapter 185.\n",
            "No audio found for chapter 185.\n",
            "No text found for chapter 186.\n",
            "No audio found for chapter 186.\n",
            "No text found for chapter 187.\n",
            "No audio found for chapter 187.\n",
            "No text found for chapter 188.\n",
            "No audio found for chapter 188.\n",
            "No text found for chapter 189.\n",
            "No audio found for chapter 189.\n",
            "No text found for chapter 190.\n",
            "No audio found for chapter 190.\n",
            "No text found for chapter 191.\n",
            "No audio found for chapter 191.\n",
            "No text found for chapter 192.\n",
            "No audio found for chapter 192.\n",
            "No text found for chapter 193.\n",
            "No audio found for chapter 193.\n",
            "No text found for chapter 194.\n",
            "No audio found for chapter 194.\n",
            "No text found for chapter 195.\n",
            "No audio found for chapter 195.\n",
            "No text found for chapter 196.\n",
            "No audio found for chapter 196.\n",
            "No text found for chapter 197.\n",
            "No audio found for chapter 197.\n",
            "No text found for chapter 198.\n",
            "No audio found for chapter 198.\n",
            "No text found for chapter 199.\n",
            "No audio found for chapter 199.\n",
            "No text found for chapter 200.\n",
            "No audio found for chapter 200.\n",
            "No text found for chapter 201.\n",
            "No audio found for chapter 201.\n",
            "No text found for chapter 202.\n",
            "No audio found for chapter 202.\n",
            "No text found for chapter 203.\n",
            "No audio found for chapter 203.\n",
            "No text found for chapter 204.\n",
            "No audio found for chapter 204.\n",
            "No text found for chapter 205.\n",
            "No audio found for chapter 205.\n",
            "No text found for chapter 206.\n",
            "No audio found for chapter 206.\n",
            "No text found for chapter 207.\n",
            "No audio found for chapter 207.\n",
            "No text found for chapter 208.\n",
            "No audio found for chapter 208.\n",
            "[01:53.480 --> 01:55.800]  And here, let's click on install.\n",
            "[01:55.800 --> 01:57.760]  Next, let's click on continue.\n",
            "[01:57.760 --> 01:59.440]  Next, you should see a message saying\n",
            "[01:59.440 --> 02:02.480]  that Google Collaboratory was connected to Google Drive.\n",
            "[02:02.480 --> 02:05.080]  Let's click on okay, and look at that.\n",
            "[02:05.080 --> 02:07.080]  It has successfully been installed.\n",
            "[02:07.080 --> 02:08.380]  Let's click on done.\n",
            "[02:08.380 --> 02:10.560]  Now, you can close out this window.\n",
            "[02:10.560 --> 02:12.840]  Let's now go back to the top left-hand corner,\n",
            "[02:12.840 --> 02:14.640]  click on the new button again,\n",
            "[02:14.640 --> 02:16.200]  then go down to more,\n",
            "[02:16.200 --> 02:18.000]  and here you should now see an option\n",
            "[02:18.000 --> 02:19.720]  for Google Collaboratory.\n",
            "[02:19.720 --> 02:20.960]  Let's click on this one.\n",
            "No text found for chapter 209.\n",
            "No audio found for chapter 209.\n",
            "No text found for chapter 210.\n",
            "No audio found for chapter 210.\n",
            "No text found for chapter 211.\n",
            "No audio found for chapter 211.\n",
            "No text found for chapter 212.\n",
            "No audio found for chapter 212.\n",
            "No text found for chapter 213.\n",
            "No audio found for chapter 213.\n",
            "No text found for chapter 214.\n",
            "No audio found for chapter 214.\n",
            "No text found for chapter 215.\n",
            "No audio found for chapter 215.\n",
            "No text found for chapter 216.\n",
            "No audio found for chapter 216.\n",
            "No text found for chapter 217.\n",
            "No audio found for chapter 217.\n",
            "No text found for chapter 218.\n",
            "No audio found for chapter 218.\n",
            "No text found for chapter 219.\n",
            "No audio found for chapter 219.\n",
            "No text found for chapter 220.\n",
            "No audio found for chapter 220.\n",
            "No text found for chapter 221.\n",
            "No audio found for chapter 221.\n",
            "No text found for chapter 222.\n",
            "No audio found for chapter 222.\n",
            "No text found for chapter 223.\n",
            "No audio found for chapter 223.\n",
            "No text found for chapter 224.\n",
            "No audio found for chapter 224.\n",
            "No text found for chapter 225.\n",
            "No audio found for chapter 225.\n",
            "No text found for chapter 226.\n",
            "No audio found for chapter 226.\n",
            "No text found for chapter 227.\n",
            "No audio found for chapter 227.\n",
            "No text found for chapter 228.\n",
            "No audio found for chapter 228.\n",
            "No text found for chapter 229.\n",
            "No audio found for chapter 229.\n",
            "No text found for chapter 230.\n",
            "No audio found for chapter 230.\n",
            "No text found for chapter 231.\n",
            "No audio found for chapter 231.\n",
            "No text found for chapter 232.\n",
            "No audio found for chapter 232.\n",
            "No text found for chapter 233.\n",
            "No audio found for chapter 233.\n",
            "No text found for chapter 234.\n",
            "No audio found for chapter 234.\n",
            "No text found for chapter 235.\n",
            "No audio found for chapter 235.\n",
            "No text found for chapter 236.\n",
            "No audio found for chapter 236.\n",
            "No text found for chapter 237.\n",
            "No audio found for chapter 237.\n",
            "No text found for chapter 238.\n",
            "No audio found for chapter 238.\n",
            "No text found for chapter 239.\n",
            "No audio found for chapter 239.\n",
            "No text found for chapter 240.\n",
            "No audio found for chapter 240.\n",
            "No text found for chapter 241.\n",
            "No audio found for chapter 241.\n",
            "No text found for chapter 242.\n",
            "No audio found for chapter 242.\n",
            "No text found for chapter 243.\n",
            "No audio found for chapter 243.\n",
            "No text found for chapter 244.\n",
            "No audio found for chapter 244.\n",
            "[02:20.960 --> 02:24.280]  This drops us into the Google Collaboratory space,\n",
            "[02:24.280 --> 02:26.980]  and at first glance, it might look a little bit intimidating,\n",
            "[02:26.980 --> 02:29.520]  but trust me, this is going to be so easy,\n",
            "[02:29.520 --> 02:31.720]  and the results are going to be so good.\n",
            "[02:31.720 --> 02:33.400]  In the top left-hand corner,\n",
            "[02:33.400 --> 02:35.480]  first off, let's give our file a name.\n",
            "[02:35.480 --> 02:38.320]  This way, you could find your way back to this in the future.\n",
            "[02:38.320 --> 02:39.800]  I'll click on Untitled.\n",
            "[02:39.800 --> 02:40.760]  Let's double-click on that,\n",
            "[02:40.760 --> 02:43.320]  and here I'll type in Transcribe Audio.\n",
            "[02:43.320 --> 02:44.360]  Here, I'll click away,\n",
            "[02:44.360 --> 02:46.080]  and that's now the name of the file.\n",
            "[02:46.080 --> 02:49.000]  Next, let's click on the menu titled Runtime,\n",
            "No text found for chapter 245.\n",
            "No audio found for chapter 245.\n",
            "No text found for chapter 246.\n",
            "No audio found for chapter 246.\n",
            "No text found for chapter 247.\n",
            "No audio found for chapter 247.\n",
            "No text found for chapter 248.\n",
            "No audio found for chapter 248.\n",
            "No text found for chapter 249.\n",
            "No audio found for chapter 249.\n",
            "No text found for chapter 250.\n",
            "No audio found for chapter 250.\n",
            "No text found for chapter 251.\n",
            "No audio found for chapter 251.\n",
            "No text found for chapter 252.\n",
            "No audio found for chapter 252.\n",
            "No text found for chapter 253.\n",
            "No audio found for chapter 253.\n",
            "Text for chapter 254 downloaded.\n",
            "No audio found for chapter 254.\n",
            "No text found for chapter 255.\n",
            "No audio found for chapter 255.\n",
            "No text found for chapter 256.\n",
            "No audio found for chapter 256.\n",
            "No text found for chapter 257.\n",
            "No audio found for chapter 257.\n",
            "No text found for chapter 258.\n",
            "No audio found for chapter 258.\n",
            "No text found for chapter 259.\n",
            "No audio found for chapter 259.\n",
            "No text found for chapter 260.\n",
            "No audio found for chapter 260.\n",
            "[02:49.040 --> 02:49.880]  and right here,\n",
            "[02:49.880 --> 02:52.320]  there's the option for Change Runtime Type.\n",
            "[02:52.320 --> 02:53.520]  Let's click on that,\n",
            "[02:53.520 --> 02:55.480]  and that opens up this dialog\n",
            "[02:55.480 --> 02:58.520]  where we can choose the hardware accelerator.\n",
            "[02:58.520 --> 03:02.840]  Be sure to select GPU, or a graphics card.\n",
            "[03:02.840 --> 03:04.920]  It turns out that graphics cards\n",
            "[03:04.920 --> 03:08.040]  run these models extremely well.\n",
            "[03:08.040 --> 03:10.160]  Next, let's click on Save.\n",
            "[03:10.160 --> 03:13.040]  Next, we need to install Whisper AI,\n",
            "[03:13.040 --> 03:15.120]  so let's go up to this field right up above\n",
            "[03:15.120 --> 03:16.600]  where we can enter in code,\n",
            "[03:16.600 --> 03:18.880]  and here I'll enter this in.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-75091e5c856c>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio_data, sr = librosa.load(audio_file_path, sr=None)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/audio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/audio': Format not recognised.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c2c90a364273>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-c2c90a364273>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maudio_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/audio'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvisualize_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-75091e5c856c>\u001b[0m in \u001b[0;36mvisualize_audio\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Load audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Plot audio waveform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/audio'"
          ]
        }
      ],
      "source": [
        "# Main function to execute the workflow\n",
        "def main():\n",
        "    scrape_audio_and_text()\n",
        "    audio_data, text_data = prepare_data()\n",
        "    audio_data_path = '/content/audio'\n",
        "    visualize_audio(audio_data_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP1p_i8lpTZ-"
      },
      "source": [
        "Additional Step:Improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We need to use a method to properly encode the url unlike unquote which we did but did not do much\n",
        "\n",
        "2. We can also manually inspect and copy paste the link and iterate over for extraction for EDA exploration.\n",
        "\n",
        "3. for text analysis, we can use transcription like we did in task 1 from audio and compare it with downloaded text as graound truth to know and quantify the transcription methodology by different similarity metrics such as Word Error Rate (WER), Character Error Rate (CER), and Levenshtein distance to quantify the transcription accuracy.\n",
        "\n",
        "4. and finally can optimise by performing spelling or grammer checking and hence make a vocabulary dictionry for future use."
      ],
      "metadata": {
        "id": "MxP8m2FcFkH2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}